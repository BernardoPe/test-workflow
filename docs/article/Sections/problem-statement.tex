\section{Problem Statement}

In this section, we examine the challenges of implementing Progressive
Server-Side Rendering (PSSR) in modern web applications, with a focus on the
limitations of current template engine designs. Our goal is to broaden the
range of options available for PSSR, particularly within JVM-based frameworks.

Reactive streams, such as those based on \texttt{Observable} (from RxJava) and
\texttt{Flow} (from the Java 9+ standard library), are abstractions that enable
progressive server-side rendering (PSSR) in environments utilizing
\textit{internal} DSLs. These abstractions provide a non-blocking, asynchronous
way to handle data streams, making them ideal for generating and sending HTML
content incrementally as data becomes available. In PSSR, the server does not
wait for the entire data model to be ready before beginning to render HTML.
Instead, it processes and streams each piece of data to the client as soon as
it arrives. Reactive types like \texttt{Observable<T>} or \texttt{Flow<T>}
facilitate this by representing data as a sequence of asynchronous events.
These streams emit values over time and support backpressure, allowing the
rendering engine to consume data at a manageable rate without overwhelming
system resources. A reactive stream might emit a sequence of
\texttt{Presentation} objects, each representing a talk in a conference
schedule. As each \texttt{Presentation} is emitted by the \texttt{Observable}
or \texttt{Flow}, the internal DSL-based engine—such as HtmlFlow—can render the
corresponding HTML fragment and immediately flush it to the client. This
approach is demonstrated in \autoref{lst:presentation-observable}, where each
presentation is rendered asynchronously as it is emitted by an
\texttt{Observable}, and in \autoref{lst:presentation-flow}, which shows an
equivalent coroutine-based implementation using Kotlin's \texttt{Flow}. Both
examples highlight how internal DSLs can natively integrate with reactive types
to enable non-blocking, progressive rendering on the server side.

\lstset{style=listingstyle}
\begin{lstlisting}[
    language=Kotlin,
    basicstyle=\scriptsize\ttfamily,
    numbers=none,
    caption={\textit{HtmlFlow} presentation template with \texttt{Observable}},
    label={lst:presentation-observable}
]
await { div, model: Observable<Presentation>, onCompletion ->
    model
        .doOnNext { 
            presentationFragmentAsync
                .renderAsync(it)
                .thenApply { frag -> div.raw(frag) }
        }
        .doOnComplete { onCompletion.finish() }
        .subscribe()
}
\end{lstlisting}
\hfil
\begin{lstlisting}[
    language=Kotlin,
    basicstyle=\scriptsize\ttfamily,
    numbers=none,
    label={lst:presentation-flow},
    caption={\textit{HtmlFlow} presentation template with \texttt{Flow}},
]
suspending { model: Flow<Presentation> ->
    model.collect {
        presentationFragmentAsync
            .renderAsync(it)
            .thenApply { frag -> raw(frag) }
    }
}
\end{lstlisting}

By contrast, template engines that use \textit{external} DSLs—such as JStachio,
Thymeleaf, or Handlebars—typically define templates within static HTML
documents using custom markers, and rely on blocking interfaces like
\texttt{Iterable} or \texttt{List}. These interfaces require the entire data
model to be materialized before rendering can begin, which blocks server
threads during template expansion and significantly limits scalability under
high concurrency. These interfaces require the entire data model to be
materialized before rendering can begin, which blocks server threads during
template expansion and significantly limits scalability under high concurrency.
Some reactive libraries, such as RxJava, provide bridging mechanisms like
\texttt{Observable.blockingIterable()}, which allows asynchronous data sources
to be exposed as Iterable by blocking the thread until new items are available.
While useful for compatibility with traditional APIs, this approach
reintroduces blocking behavior and undermines the benefits of non-blocking
I/O—especially under high concurrency. \autoref{lst:presentation-jstachio}
illustrates this model using a JStachio template, where the engine performs a
blocking loop over \texttt{presentationItems}.

\vspace{1cm}

\lstset{style=listingstyle}
\begin{lstlisting}[
  language=Kotlin,
  numbers=none,
  basicstyle=\scriptsize\ttfamily,
  caption={Presentation HTML template using \textit{JStachio}},
  label={lst:presentation-jstachio}
]
{{#presentationItems}}
<div class="card mb-3 shadow-sm rounded">
    <div class="card-header">
        <h5 class="card-title">
            {{title}} - {{speakerName}}
        </h5>
    </div>
    <div class="card-body">
        {{summary}}
    </div>
</div>
{{/presentationItems}}
\end{lstlisting}

Despite these performance limitations, external DSLs remain popular due to
several advantages:

\begin{enumerate}
    \item \emph{Separation of Concerns}: HTML templates are decoupled from application logic, enabling front-end developers to contribute without modifying back-end code.
    \item \emph{Cross-Language Compatibility}: External DSLs are portable across languages and frameworks, easing integration in multi-language environments.
    \item \emph{Familiarity}: Many developers are comfortable with HTML syntax, lowering the barrier to entry and improving maintainability.
\end{enumerate}

These strengths make external DSLs appealing—even when they come at the cost of
blocking, synchronous rendering. However, this tradeoff becomes critical under
high concurrency, where blocking threads severely degrades throughput. Emerging
features in the Java ecosystem, particularly \textit{virtual threads}
introduced in Java 21 as part of Project Loom, offer a promising solution to
this challenge. Virtual threads drastically reduce the overhead of blocking
operations by decoupling thread execution from OS-level threads. As a result,
engines that rely on blocking interfaces—like those used in
external DSLs—can potentially achieve scalability levels that approach those of
non-blocking, asynchronous engines.

% Incluir este parágrafo?
% In previous work \cite{PSSR-WISE2024}, Carvalho benchmarked the performance of
% HtmlFlow (an internal DSL) using suspendable templates within a Spring WebFlux
% application. HtmlFlow scaled efficiently to 128 concurrent users and delivered
% up to 4,000 requests per second. In contrast, blocking engines such as JStachio
% saturated at just 4 concurrent users, maxing out at around 400 requests per
% second—highlighting the scalability limitations of blocking models.This work
% builds upon those findings by evaluating whether virtual threads can close this
% performance gap for blocking template engines. Specifically, we aim to
% determine whether external DSLs—traditionally unsuitable for PSSR due to their
% reliance on blocking APIs—can become viable for progressive rendering when
% powered by virtual threads.

If successful, this approach would enable developers to reap the ergonomic
benefits of external DSLs while maintaining scalable performance, without
adopting complex asynchronous paradigms. It would also simplify the
implementation of PSSR across a broader range of frameworks and engines, making
the technique more accessible to mainstream web development.